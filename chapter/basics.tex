%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Basics}
\label{cha:basics}
\section{Definitions}

\paragraph{Lexeme}
A lexeme is a sequence of characters on the character stream that matches a specific token pattern and is identified by the lexical analyzer as an instance of that token. \cite{DragonBook}

\paragraph{Language} 
A language is any countable set of words over some fixed alphabet. The set of all context-free languages is identical to the set of languages that is accepted by pushdown automaton. \cite{DragonBook}

\paragraph{Alphabet}
"An alphabet is any finite set of symbols." Examples of symbols are letters and digits. \cite{DragonBook}

\paragraph{Word} 
A word over an alphabet is a finite sequence of symbols drawn from that alphabet. In language theory, the terms \emph{sentence}, \emph{word} and \emph{string} are used as synonyms. \cite{DragonBook}

\paragraph{Kleene Star} 
The (Kleene) closure of a language $L$, denoted $L^*$, is the set of strings received by concatenating $L$ zero or more times. \cite{DragonBook}


\paragraph{Syntax \& Semantic}  
The syntax of a language describes its proper form, while the semantics of the language defines what it means. \cite{DragonBook}


\paragraph{Context Free Grammar (CFG)}
A context-free grammar is described by a quadruple, consisting of terminals, nonterminals, a start symbol and productions.\\
$G = (T, V, S, P)$
\begin{enumerate}
	\item \emph{Terminals} are the basic symbols from which words are formed.  They are created by the lexical analyzer.
	\item \emph{Nonterminals} are syntactic variables that denote sets of words. The sets of words denoted by nonterminals helps to define the language generated by the grammar. Nonterminals impose a hierarchical structure on the language that is essential to syntax analysis and translation.
	\item One nonterminal in a grammar is distinguished as the \emph{start symbol} which is an element of $V$
	\item The \emph{productions} of a grammar specify how terminals and nonterminals can be combined to form words . Each production consists of:
	\begin{enumerate}
		\item A nonterminal called left side of the production; this production defines some of the words denoted by the left side.
		\item The symbol \code{$\rightarrow$}  or  \code{::=} 
		\item The \emph{right side} consisting of zero or more terminals and nonterminals. The components of the \emph{body} describe one way in which words of the nonterminal at the head can be constructed.
	\end{enumerate}
\end{enumerate}
 $P$ is a finite relation from $V \rightarrow (V  \bigcup  T)^*$, where $^*$ is the Kleene star. Members of $P$ are productions of the form $u \rightarrow v$. \cite{DragonBook}


\paragraph{Tokens \& Terminals}  
A token consists of a name and an attribute value. The names are abstract symbols used by the parser for syntax analysis. These token names are often called terminals. The attribute value contains additional information. \cite{DragonBook}


\paragraph{Lexer}
A Lexer, also denoted as lexical analyzer, allows a parser to treat multi character constructs like identifiers as units called tokens during syntax analysis. \cite{DragonBook}

\paragraph{Parsing} 
"Parsing is the process of structuring a linear representation in accordance with a given grammar." \cite{ParserBook}

\paragraph{Parse Tree}
Given a context-free grammar, a parse tree according to the grammar is a tree with these properties \cite{DragonBook}:
\begin{enumerate}
	\item the start symbol is the roots label.
	\item The leafs are labeled by a terminal or by $\epsilon$.
	\item Interior nodes are labeled by nonterminals.
	\item If $A$ is a nonterminal, which labels an interior node and $X_1, X_2, . . . , X_n$ are the labels of the children of that node from left to right, then there must be a production $A  \rightarrow X_1X_2 ... X_n$. So $X_1, X_2, ... , X_n$ stand for a symbol each that is either a terminal or a nonterminal. If $A\rightarrow c$ is a production, then a node labeled A may have a single child labeled $\epsilon$ as a special case. 
\end{enumerate}

\paragraph{Meta Model} The structure of a language is captured in its metamodel. A metamodel is a model that provides the basis for constructing other, so called instance models \cite{EMP}. The Meta Model defines the Abstract Syntax and optionally the Static Semantics of a language. \cite{MDSD}

\paragraph{Meta Metamodel} A Meta Metamodel is a model that describes Meta Models. Meta Metamodels like Ecore and Meta Object Facility are self descriptive: their metaclasses can be used to describe them selfs, so they are their own Meta Model. \cite{EMF2nd}

\paragraph{Model} A Model\footnote{\raggedright With exception of XTexts ``node model'', which is no model conforming this definition. }  or instance Model is an instance of a metamodel.

\paragraph{Ambiguity} 
A grammar which can generate more than one parse tree for a given string of terminals is said to be ambiguous.\cite{DragonBook}

\paragraph{Abstract Syntax Tree (AST)}  
The abstract syntax trees  represents the hierarchical syntactic structure of a language.  Abstract syntax trees resemble parse trees to an extent. In the parse tree interior nodes represent nonterminals including "helpers" of one sort of another. In the syntax tree, these helpers typically dropped. \cite{DragonBook}

\paragraph{S-Attributed Grammar} 
An Attributed Grammar formally defines a way to attach attributes to tree nodes created in regards to production rules of a formal grammar. If the evaluation rule of ab attribute value only depends on its children, it's called a synthesized attribute. An S-Attributed Grammar is an Attributed Grammar, which is only based on \emph{synthesized} attributes. The evaluation of S-attributed grammars can be incorporated in top-down, as well as in bottom-up parsing. \cite{ParserBook}
 
\paragraph{Domain} A domain is a delimited area of knowledge or interest. \cite{MDSD}

\paragraph{Domain Specific Language} A Domain Specific Language is a Programming Language for a domain. It consists of abstract and concrete syntax, static semantics as well as a clearly defined semantic of the language elements. \cite{MDSD}

\paragraph{Abstract Syntax} Meta Model elements and their relation are the abstract syntax of a language. \cite{MDSD}

\paragraph{Concrete Syntax} In contrast to the Abstract Syntax, the Concrete Syntax defines the actual representation of the language. \cite{MDSD}

\paragraph{Static Semantics} The Static Semantics defines well formedness constraints. \cite{MDSD}
 
\paragraph{Extended Backus-Naur Form (EBNF)} 
The Backus-Naur Form (BNF) is a notation to describe context-free grammars. It is based on \cite{BNF} and defines \code{:=} and \code{|} as metaliguistic connectives and characters enclosed by \code{<} and \code{>} as metalinguistic variables.
\begin{xtxt}
 <nonterminal> ::= sequence
\end{xtxt}
The sequence consists of one or more nonterminals or terminals and may contain a vertical bar to indicate a choice. The whole sequence replaces the symbol on the right. The extended Backus-Naur Form (EBNF) is a family of BNF dialects with the same power as BNF, but with improved readability. Common extensions are grouping, the Kleene star denoting a zero or more multiplicity, the Kleene cross denoting a multiplicity of one or more, and an option denoting a multiplicity of zero or one. \cite{ParserBook}

\paragraph{Parse Forest} 
A set of parse trees. If duplicated subtrees are combined, the resulting structure is called a parse graph. \cite{ParserBook}

\paragraph{Sentential Forms}   
The intermediate form for creating sentences from a formal grammar are called sentential forms. \cite{ParserBook}

\paragraph{Parsing as Constraint Satisfaction Problem (CSP)} 
Beside answering the question if a word is part of a language, a practical reason for parsing is to obtain the structure of a word to help processing or translating it further. To parse a word according to a grammar means to reconstruct the production tree that indicates how the given word can be produced from the given grammar. This is a specific Constraint Satisfaction Problem (CSP): To consume all tokens on the input stream constrained by the grammar rules. It is possible to build the parse tree by the path taken, or the sequence of rule applications by the parser.  Top-down parser identify the production rules in post-order, bottom-up parsers tend to identify them in postfix order. This is called Linearization of the Parse Tree. \cite{ParserBook}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

